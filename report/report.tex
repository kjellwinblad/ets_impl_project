%\documentclass[aps,pre,preprint,groupedaddress,nofootinbib]{revtex4}
\documentclass[aps,pre,preprint,nofootinbib]{revtex4}
%\documentclass[aps,twocolumn,pre,nofootinbib]{revtex4}   % list options between brackets
\usepackage{listings}              % list packages between braces
\usepackage{graphicx}
\usepackage{epstopdf}
%\usepackage{cite}

% type user-defined commands here

\begin{document}

\title{Erlang Term Storage Implementation}
\author{Kjell Winblad and Stavros Aronis}
\date{\today}


\begin{abstract}

  This report describe in detail how the Erlang Term Storage (ETS) is implemented.
  The report is created in the RELEASE project as the first step towards creating a more scalable ETS implementation.
  ETS tables are commonly used to share data between processes in Erlang programs.
  It is important to have a very good ETS implementation because shared data is often the bottleneck in concurrent applications.
  The main goals of the report are:
  \begin{itemize}
   \item to get an understanding of the current implementation of the different ETS tables
   \item and to communicate this knowledge to for example the Erlang OTP team. 
  \end{itemize} 

\end{abstract}

\maketitle

\section{Introduction}

Erlang Term Storage (ETS) support is included in Erlang runtime system.
ETS tables are used to store Erlang tuples outside the processes' heaps.
This prevents garbage collection from copying these tuples while collecting memory space from a process' heap and can also be used to efficiently share data between processes. %I don't understand the part about garbage collection
An Erlang ETS table behaves as if a dedicated process serves requests for insertions, lookups and other common operations on a key value dictionary, but is implemented in a more efficient way.
Most of the operations on an ETS table are implemented as built-in functions (BIFs) of the Erlang runtime system. 
An ETS table can be accessed by either a \emph{table identifier} (TID) or an atom (in case of a \emph{named} table).
In either case the identifier for the table is returned by the call to the \verb|ets:new/2| BIF.
The \verb|ets:new/2| BIF can take a list of options that specify: 

\begin{itemize}
\item 
  The access level which can be \verb|private|, \verb|protected| and \verb|public|.
  See the Erlang documentation for \verb|ets:new| for more information about these options.
\item
  Whether the table is a \verb|named_table|, in which case the atom provided as a table name can be used instead of the TID in table operations.
\item 
  Whether the table type shall be \verb|set|, \verb|bag |, \verb|duplicate_bag| or \verb|ordered_set|. 
  See section~\ref{sec:table_types} for information about the data-structures used in the different table types.
\item 
  Whether fine grained locking is enabled for read and write operations (specified with the options \verb|write_concurrency| and \verb|read_concurrency|). 
  See section~\ref{sec:concurrency_options} and \ref{sec:benchmark} for more information about these options.
\end{itemize}

ETS tables are owned by the creating process as long as the creating process is alive unless the ownership has been passed to another process with the BIF \verb|ets:give_away|.
If the owner of an ETS table terminates the table will be deleted, if the \verb|heir| option is not set.
The programmer can use the \verb|heir| option, or the \verb|set_heir| BIF to specify a process that will inherit the table when the current owner terminates. 
If a process has been specified with the \verb|heir| option it will receive a message signalling the transfer of table ownership, when the previous owner terminates.

\subsection{Overview of Table Operations}

This section gives an overview of the most fundamental ETS table operations. 
See the Erlang documentation\footnote{http://www.erlang.org/doc/man/ets.html} for ETS tables for a complete description of all table operations. 
See section~\ref{sec:table_types} for information about the data-structures used in the tables.

\begin{description}
 \item[lookup(Tab, Key) $\rightarrow$ [Object]] 
 Returns a list of elements that have the given key. 
 Calls to \verb|lookup| and \verb|insert| can be done concurrently if \verb|read_concurrency| is activated.
 \item[insert(Tab, ObjectOrObjects) $\rightarrow$ true]
 Insert the given object (or objects, if the parameter is a list of objects) to the table.
 Several inserts can be done concurrently if \verb|write_concurrency| is activated when \verb|set|, \verb|bag | or \verb|duplicate_bag| is used.
 If a write operation can be done concurrently, a read operation involving the same kay can also be done concurrently.
 \item[insert\_new(Tab, ObjectOrObjects) $\rightarrow$ true]
 This operation will insert the given object or objects if no object with the same key as any of the object(s) exists. 
 If a key already exists the operation will return false.
 \item[delete(Tab, Key) $\rightarrow$ true] Deletes all objects with the given key from the table.
 \item[first(Tab) $\rightarrow$ Key $|$ \texttt{end\_of\_table} ] Returns the first key in the table. If the table is of the \verb|ordered_set| type, the first key in Erlang term order will be returned. If the table is of any other type, the first key according to the table's internal order will be returned. If the table is empty, \verb|end_of_table| will be returned.
 \item[last(Tab) $\rightarrow$ Key $|$ \texttt{end\_of\_table} ] Returns the last key in the table.
\end{description}

\section{Previous Work}

  Scott Lystig Fritchie has suggested a new ETS table type based on Judy-arrays~\cite{ScottEtsJudy}.
  In~\cite{ScottEtsJudy}, the performance of a Judy-array based implementation of ETS tables is experimentally compared to the currently available table types.
  For large table sizes the operations lookup, insert and update seems to be faster with the Judy-array based implementation.
  However term deletion and table traversal seems to be slower in the Judy-array based implementation.
  The benchmarks in~\cite{ScottEtsJudy} do not test how the implementation performs when operations are performed concurrently.
  
  Patrik Nyblom has suggested the addition of software transactional memory (STM) support for Erlang ETS tables~\cite{PatrikErlangTrans}.
  STM support could be added to Erlang with only minor changes to the ETS implementation \cite{PatrikErlangTrans}.
  The implementation suggested in~\cite{PatrikErlangTrans} would not effect the performance of ETS when the transactional features are not used.
  At the same time it could increase parallelism for use cases where the only alternative without transactional memory support is to serialize all operations on the ETS table (or tables).
  Benchmark results provided in~\cite{PatrikErlangTrans} for a prototype of ETS with transactional memory, show that transactional memory support for ETS could make some use cases much more scalable with the number of cores.
  

\section{Handling of Tables}

The infrastructure for the handling of tables is described in this section. 
An overview of the data-structures involved is provided in section~\ref{sec:tables_overview}.
How locking is done when tables are accessed concurrently is described in section~\ref{sec:tables_locking}.

\subsection{Overview} \label{sec:tables_overview}

\subsubsection{Global data structures}

\begin{description}
  \item[meta\_main\_table] Contains all the tables. TIDs map to a slot.
  \item[meta\_name\_table] Keys are atoms, values are TIDs.
  \item[meta\_pid\_to\_tab] Maps processes (PIDs) to tables owned by them.
  \item[meta\_pid\_to\_fixed\_tab] Maps processes (PIDs) to tables that are
    fixated by them.
\end{description}

\subsection{Locking} \label{sec:tables_locking}

Different levels of locking are required for each operation on an ETS table.

\begin{itemize}
\item Creation and deletion of a table require the acquisition of the write lock protecting the \verb|meta_main_table|.
\item Creation, deletion and renaming of a named table also require the acquisition of the write lock protecting the \verb|meta_name_table|.
\item Read and write operations on a table require the acquisition of the appropriate table locks.
  Using the default options, each table has just one main lock, used for all entries.
  Depending on the type and the options specified when a table is created, two read and write operations for different keys can be allowed to run in parallel, by locking only parts of the table.
  We give further details in section~\ref{sec:table_types}.
\end{itemize}

\section{Table Types} \label{sec:table_types}

Tables of type \verb|set|, \verb|bag| and \verb|duplicate_bag| do not impose any particular order between their entries.
These tables are implemented in the runtime system as hash tables.
In contrast, \verb|ordered_set| tables have their entries ordered according to their keys and are therefore implemented as AVL trees.
The runtime system is structured in such a way that operations which are transparent to the underlying implementation of a table are handled with normal C functions, while operations that depend on the implementation are dispatched from the equivalent of a method table.

\subsection{Hash tables}

Hash tables distribute their key-value entries to buckets, depending on a hash value generated using the key.

\subsubsection{Fine Locking}

Protected and public hash tables support fine locking if created with the \verb|write_concurrency| option.
In this case an array of locks is allocated during table creation and each lock protects a subset of the buckets.
The size of the lock array is defined at \emph{compile time} and is currently set to 16.
Each lock protects those buckets whose id modulo 16 equals the slot's id.

\subsubsection{Data Structure}

The current implementation of ETS tables is based on linear dynamic hash tables~\cite{Larson}.
The main data structure is called ``extended segment'' and has two parts:
\begin{enumerate}
  \item A ``bucket'' section, containing 256 pointers to lists of the key-value pairs that belong to the respective bucket.
    This corresponds to the regular ``chaining'' implementation of a hash table.
  \item A ``segment'' section, pointing to ``bucket'' sections.
\end{enumerate}
The runtime system can also allocate plain ``bucket'' sections, without ``segment'' sections attached.
As an invariant, the entry point for all access is a ``current'' extended segment, but there might also exist ``previous'' extended segments.

As an invariant, a continuous range of buckets (starting with bucket 0) marks the  ``active'' buckets.
The index of the highest active bucket is stored as \verb|nactive|.

To operate with some element of the table, the hash value of the key of the element is first calculated.
This hash value is then mapped to the id of a bucket of the table, using the least significant bits of the hash value.
If the bucket is active, this is the actual index of the bucket.
If the bucket is not active, another significant bit is dropped, and the bucket at half the previous index is used instead.

The bucket id can be divided into two parts: a segment address and a bucket offset.
Initially the segment address is used as an index on the segment section of the current ``extended segment'', to find the base pointer of a bucket section.
Then the bucket offset is used to find the bucket itself in the respective bucket section.

\begin{figure}[htb]
\centering
\includegraphics[width=1.0\textwidth]{hash_table_structure.eps}
\caption{Hash table structure} 
\label{fig:hash_table_structure}
\end{figure}
\subsubsection{Growing}

Growing happens by splitting a bucket, moving elements to the bucket after the one that is currently active.
The bucket to be split is the one at half the new bucket's index.
Growing happens when the load of the table exceeds a predefined value.
Currently this value is set so that if a uniform distribution of elements is assumed, each bucket has a chain length of 6.
If the segment address of the new bucket corresponds to a slot in the index segment that is currently not pointing to a bucket section, a new plain bucket section is allocated and the slot is now pointing to its first entry.
If this operation would assign a slot in the last slot of the segment section of currently active extended segment, a new extended segment is allocated instead, with more slots in its segment section.
The first extended segment has 2 slots in its segment section.
The second extended segment has 256 slots in its segment section.
Each next extended segment has 128 more slots in its segment section than the previous.
After a new extended segment is allocated, all the pointers from the segment section of the old extended segment are copied into the low slots of the segment section of new extended segment.
This leads to duplication, but enables reaching the contents of a bucket by using the segment section of just the current extended segment.
The new extended segment does not immediately replace the old one.
This happens when yet another segment must be allocated.
(This will be a plain segment, stored in the segment section of the new extended segment.)

\subsubsection{Shrinking}

Shrinking works in the reverse direction of growing.
When the load falls below a preset limit, the active bucket with the highest index is 

\subsection{Set}     % section 2.1
\subsection{Bag}
\subsection{Duplicate Bag}


\subsection{Ordered Set}


\section{Concurrency Options} \label{sec:concurrency_options}

\subsection{Write Concurrency}

\subsection{Read Concurrency}

\section{Fixation}

A process can call \texttt{ets:safe\_fixtable(Table, true $|$ false)} to put a fixation on a table implemented with a hash table (\verb|set|, \verb|bag| or \verb|duplicate_bag|).
When a table is fixed, a sequence of \verb|first/1| and \verb|next/2| calls are guaranteed to succeed and each object in the table will only be returned once, even if objects are removed or inserted during the traversal.
The keys for new objects inserted during the traversal may be returned by \verb|next/2| (it depends on the internal ordering of the keys).
In practice, this translates to the following 2 guarantees:

\begin{enumerate}
  \item Keys will not totally disappear from the table.
    A key can thus be used as an iterator to find the next key in iteration sequence.
    Note however that this does not mean that (pointers to) table objects are guaranteed to be maintained while the table is fixated.
    A BAG or DBAG may actually remove objects as long as there is at least one object left in the table with the same key (alive or pseudo-deleted).
    \item Objects will not be moved between buckets due to table grow/shrink.
      This will guarantee that iterations do not miss keys or get double-hits.
\end{enumerate}

\section{Benchmark} \label{sec:benchmark}

  A simple benchmark has been performed.
  The purpose of the benchmark is to see how the \verb|write_concurrency| and \verb|read_concurrency| options effects the performance for the different table types on a real world problem.
  The benchmark creates workers that all do \verb|lookup|s and \verb|insert|s on the same ETS table (cache).
  The benchmark was done on a computer with 64 cores.
  We run the benchmark program with all different combinations of \verb|write_concurrency|, \verb|read_concurrency| and the different table types: \verb|set| and \verb|ordered_set| with 1 to 30 workers.
  
  \subsection{Benchmark Problem}
    The benchmark program finds the minimum number of sort steps to sort an array with a few constraints.
    The array contains \emph{black} marks, \emph{white} marks and \emph{empty} positions.
    An array can be represented as for example \verb|"ebbwe"|, where \verb|e| represent \emph{empty} position, \verb|w| represent a \emph{white} mark and \verb|b| a \emph{black} mark.
    Black marks can only move in the right direction and white marks can only move in the left direction.
    In one sort step a mark can:
    \begin{itemize}
     \item move one step in the array if the neighbor position in the direction of the movement is empty or
     \item move two steps in the array if the neighbor position in the direction of the movement contains a mark and the position after the neighbor position is empty.
    \end{itemize}
    A sorted array has all white marks as far to the left in the array as possible and all black marks as far to the right in the array as possible.
    Some input arrays can not be sorted with the given constraints, e.g. \verb|"bbww"|.
    If the input array can not be sorted the program shall return $-1$.
    For example the minimum number of steps for \verb|"ebbwe"| is $5$.
    The benchmark timed the time it took to return the result for the arrays \verb|"bebebbeeeewwwbw"|, \verb|"bebebeeewewewewwe"|.
    
  \subsection{Implementation}
    The Erlang program that solves the benchmark problem is available at www.github.com\footnote{http://github.com/kjellwinblad/ets\_impl\_project/blob/master/benchmark/multi\_4.erl}.
    The program explores the the possible solutions in a breath first search manner.
    Explored configurations are saved in an ETS table to avoid repeating work.
    
    The program has one coordinator process and a number of worker processes.
    At a specific level in the search tree, the coordinator divides the configurations that needs to be explored in the next level evenly and sends them to the workers.
    The workers send a message to the coordinator if a solution is found.
    If a worker finds configuration that is not a solution, it is expanded by generating all possible configurations that can be creating by doing one sort step.
    
    Directly after a configuration is generated it is checked if it already exists in the ETS table cache with the \verb|ets:member| function.
    If it already exists, it is thrown away because the configuration has already been visited.
    Otherwise, the configuration is inserted in the ETS table with the \verb|ets:inser_new| operation.
    The return value of \verb|ets:insert_new| is checked to make sure that the configuration has not been inserted by another process between the call to \verb|ets:member| and \verb|ets:insert_new|.
    The Erlang code that is interacting with the ETS table cache in the workers can be seen in listing~\ref{li_erlang_ets_interaction}.

    \lstset{language=erlang, caption=Worker code that is interacting with ETS, label=li_erlang_ets_interaction} 
\begin{lstlisting}[float=htb] 
IsFound = ets:member(Cache, MoveArray),
case IsFound of
  false ->
    Inserted = ets:insert_new(Cache, {MoveArray}),
    case Inserted of
      true ->
        [MoveArray|all_next_step_arrays(Array, CurrentPos + 1, Cache)];
      false ->
        all_next_step_arrays(Array, CurrentPos + 1, Cache)
    end;
  true ->
    all_next_step_arrays(Array, CurrentPos + 1, Cache)
end
\end{lstlisting}
    
    A worker send back all configurations that needs to be explored in the next level to the coordinator, when it has processed all given configurations on the current level.


\subsection{Results}

  The results of the benchmark can be seen in figure~\ref{fig:benchmark_results}.
  The filled straight line labeled \emph{serial} is the performance of a serial version of benchmark program.
  The serial version can also be found at www.github.com\footnote{http://github.com/kjellwinblad/ets\_impl\_project/blob/master/benchmark/single\_1.erl}.
  The graphs with \emph{set} in the label shows the benchmark times for the table type \verb|set|.
  The graphs with \emph{ordset} in the label shows the benchmark times for the table type \verb|ordered_set|.
  A \emph{w} in the label means that the benchmark program has \verb|write_concurrency| enabled and an \emph{r} in the label means that the benchmark program has \verb|read_concurrency| enabled.
  
  
\begin{figure}[htb]
\centering
\includegraphics[width=1.0\textwidth]{benchmark.eps}
\caption{Benchmark Results} 
\label{fig:benchmark_results}
\end{figure}

  The table type \verb|set| with \verb|write_concurrency| enabled seems to give similar performance both with and without \verb|read_concurrency| enabled.
  All other configurations give similar performance to each other.
  It is not surprising that all \verb|ordered_set| configurations perform similarly since the \verb|write_concurrency| and \verb|read_concurrency| options do not effect this table type at all.
  The \verb|ordered_set| table type should theoretically have more expensive \verb|lookup| and \verb|insert| operations compared to the \verb|set| table type.
  This does not seem to not have any significant effect on this benchmark.
  
  In this particular benchmark it seems like \verb|write_concurrency| for the table type \verb|set| is particularly important for scalability.
  For the other configurations the performance seems to get worse, when more than five worker processes are used.
  It is reasonable to think that the reason for this is that the contention become higher when the number of workers is increased.

  
  
\section{Scalable ETS Suggestions}

  The benchmark that is described in section~\ref{sec:benchmark}, shows that the fine grained locking provided by the \verb|write_concurrency| option can be very important for scalability.
  The number of locks used when fine grained locking is enabled is hard coded to 16 in the current implementation.
  It would be possible to make the fine grained locking even more fine grained, since it could possibly make ETS more scalable.
  The benchmark described in section~\ref{sec:benchmark} has been run with a versions of the runtime environment with the number of locks set to 32 and 64.
  This did not seem to have any significant effect on the performance of the benchmark program.
  There might be other bottleneck in this particular benchmark that are more important.
  It would be interesting to look more deeply into how the number of locks effect the performance on other benchmarks.
  
  The benchmarks of Judy-array based ETS table implementations that are described in~\cite{ScottEtsJudy}, suggests that there are other table types that are significantly faster than the current ones for some use cases.
  There might also be be other alternative data structures for implementing ETS tables that perform better when accessed concurrently on multi core systems.
  It would be interesting to look into other concurrent table implementations and compare them with the current ETS implementation.
  
  The current ETS table implementation has no good support for use cases when more than one table operation need to be performed atomically.
  The only practical way to support that use case with the current ETS implementation is to serialize all access to the ETS table or ETS tables involved.
  Transactional support for ETS tables as suggested in~\cite{PatrikErlangTrans} could be a way to support this use case in a much more scalable way.
  
  In the current implementation of ETS, all terms that are inserted or fetched from an ETS table are copied from or to the ETS table.
  This might be expensive both in respect to time and memory if a lot of processes access the same elements in the table.
  An alternative would be to use references for terms that are stored in ETS tables. 
  Erlang already make use of references for large values of the binary data type.
  Therefore, it might be possible to reuse some existing components in the Erlang runtime system, to implement references for terms stored in the ETS tables with some potential performance benefits.
  
  The current \verb|ordered_set| table type only use one lock for the whole data structure. 
  There exist implementations of binary trees that scales much better than the current \verb|ordered_set| implementation and that have support for efficient traversal of the tree~\cite{BronsonPracTree}.
  The relaxed AVL-tree data-structures with STM inspired methods for thread safety suggested in~\cite{BronsonPracTree} could give much better scalability on a multi core computer than the existing \verb|ordered_set| implementation.
  

\bibliographystyle{unsrt}  

\bibliography{report}
  

\end{document}
